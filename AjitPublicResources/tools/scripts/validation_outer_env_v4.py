#!/usr/bin/env python
# The script creates a text file containing list of absolute paths of 
# all .vprj files in the given root directories. It then calls gnu 
# parallel with validation_inner_env_v2.py and text file and an option for 
# processor executable as the arguments, to start parallel jobs and 
# prints total number of failed cases and total time of execution 
# after complete execution of all the jobs.


# No. of parallel jobs and timeout of job can be set by user. The script
# provides help on usage, cleans compiled directory created during normal 
# execution and gives a list of unattneded but valid .c/.s files. The 
# script also generates terminal log file and jobs log file.


# Written by Piyush P. Soni
#
# 
# Modified by Madhav P. Desai
#
#
# Modified by Gauri Patrikar


import os
import sys
import shutil
import getopt
import os.path
import subprocess
import pdb

def reportError(err_message):
   print ("Error: " + err_message)



def setGlobals(work_dir):

   global ajit_project_home
   global ajit_C_home
   global validation_exec_location
   global validation_C_exec_location

   # get location of this script
   global script_pathname 
   global validation_script_path

   # absolute path of file to store .vprj paths
   global path_src_file_list_file

   # give the search file 
   global search_file

   # path of validation_parallel2.py
   global path_validation_inner 
 
   # path joblogfile
   global path_joblogfile

   # path terminal log file
   global path_term_log 

   ret_val = 0
   ajit_project_home = os.environ.get('AJIT_PROJECT_HOME')
   if (ajit_project_home == None):
	reportError("environment variable AJIT_PROJECT_HOME not defined")
	ret_val = 1


   # absolute path of file to store .vprj paths
   path_src_file_list_file = work_dir + "/src_file_list_file.txt"

   # give the search file 
   search_file = '.vprj'

   # path of validation_parallel2.py
   path_validation_inner = ajit_project_home + "/tools/scripts/validation_inner_env_v4.py"
 
   # pat/h joblogfile
   path_joblogfile = work_dir + "/validation.job.log.txt"

   # path terminal log file
   path_term_log = work_dir + "/validation.console.log.txt"
  
   # give path of processor executable
   path_proc_exec =  " " 

   return ret_val

def array (temp, dirname, names):

        # write absolute paths of .vprj in a text file
	# create directories once
	# compiled/ folder to store compiled files and .results
	# log/ folder for storing log files
	# trace_files/ folder for storing trace files
	
	srch_file = temp[0]
	obj = temp[1]
	ignore_fpu = temp[2]
	generate_trace = temp[3]
	
	# get paths of the search file
	for name in names:
		if name.endswith(srch_file):

			split_dirname = dirname.split("/") 
			path_log_fold = os.path.join (dirname, "log")	
			if not os.path.exists (path_log_fold) :
				os.makedirs (path_log_fold)
				
			path_compiled_fold = os.path.join (dirname, "compiled")
			if not os.path.exists (path_compiled_fold) :
				os.makedirs (path_compiled_fold)

			path_trace_fold = os.path.join (dirname, "trace_files")
			if not os.path.exists (path_trace_fold) :
				os.makedirs (path_trace_fold)

			path_srch_file = os.path.join (dirname, name)		
					
			# write all .vprj paths in the file		
			obj.write(path_srch_file + "\n") 
	return
	

def clean_all (srch_file, dirname, names):
	
	# clear c, assembly, log directories generated by previous execution
	# get paths of the search file only once every loop
	for name in names:
		if srch_file in name:

			# delete compiled directory
			path_compiled_fold = os.path.join (dirname, "compiled")
			if os.path.exists (path_compiled_fold) :				
				shutil.rmtree (path_compiled_fold)
				
			# delete log directory
			path_assembly_fold = os.path.join (dirname, "log")
			if os.path.exists (path_assembly_fold) :				
				shutil.rmtree (path_assembly_fold)				
	return

#removing all trace-file directory
def clean_trace (srch_file, dirname, names):
	for name in names:
		if srch_file in name:
			path_trace_fold = os.path.join (dirname, "trace_files")
			if os.path.exists (path_trace_fold) :				
				shutil.rmtree (path_trace_fold)				
	return

	
def help_sec ():

	print " "
	print " -----------------------------------------------------------------------------------------------------------"
	print " USAGE:"
	print "        validation_outer_env_v4.py [OPTIONS] [-t TIMEOUT_IN_SECONDS] [-j JOBS_TO_RUN_IN_PARALLEL] [-E EXECCUTABLE_PATH] PATHS..."
	print " -----------------------------------------------------------------------------------------------------------" 
	print " ------------------------"
	print " OPTIONS:"
        print "      -p: uses remmaped file while running C model, requires vmap.txt in same directory as vprj file"
        print " "
        print "      -L: uses linkerscript present in same directory as vprj file, requires it to be named as Linkerscript.lnk "
        print " "
	print "      -l : Generate a log of register writes"
	print "            The files are generated in trace_files/ folder"
	print  "            with extension .C_trace for C model and .Aa_trace for Aa model"
	print " "
	print "      -s : Run in single-stepping mode"
	print "            Relevant only for Aa/VHDL/FPGA model."
	print ""
	print "      -T : Generate a detailed trace of activity for each instruction "
	print "           The trace file is generated in trace_files/ folder"
	print "            with extension .long_trace"
	print "           (CAUTION : A trace file can get very large)"
	print " ------------------------"
	print " CLEANUP:"
	print "      validation_outer_env_v3.py -c PATHS..."
	print "           cleans up the compiled/ log/ and trace_files/ "
	print "           folders recursively from PATH"
	print " -----------------------------------------------------------------------------------------------------------"
	print " For multicore tests Specify no of cores, threads and version as follows in .vprj file-\n CORES = 1/2/3/4\n THREADS = 1/2\n VERSION =32/64 "
        print " ----------------------------------------------------------------------------------------------------------"

	return
	

def main ():
	
	temp = []
	jobs = ""
	timeout = ""
	absolute_path = []
	ignore_fpu = ""
	generate_detailed_trace = ""
	trace_option = ""
        remap = ""
        link = ""
	single_stepping_enabled = ""
	generate_trace = 0

	# main logs will be created in work-dir
	work_dir = os.getcwd()
	glob_status = setGlobals(work_dir)
        if(glob_status):
		return 1

   	# get location of this script
   	script_pathname = os.path.dirname(sys.argv[0])        
   	validation_script_path= os.path.abspath(script_pathname) 	#script is stored in this directory

	# options
	arg_list = sys.argv[1:]
        opts,args = getopt.getopt(arg_list,'j:t:E:c,h,l,s,T,p,L')

	#print " all relative paths = %s" %args
	if(len(opts)==0 or (opts[0][0]=='-h')):
		#print help, and return,
		help_sec();
		return 1
	elif(len(args)==0):
		print "*** ERROR ***: no paths were provided"
		#print help, and return,
		help_sec();
		return 1
	
	# get absolute paths from relative paths
	for abs_path in args:
		absolute_path.append (os.path.abspath (abs_path))
		
	args = absolute_path
	#print "all absolute paths = %s" %args

	
        executable_path = None
	for option, parameter in opts : 
		#print "option = %s" %option; print "parameter = %s" %parameter; print "opts = %s" %opts; print "args = %s" %args; print "arg_list = %s" % arg_list

		# clear compiled directory
		if option == '-c' :	
			for topdir in args:
				if os.path.exists (topdir):
					os.path.walk (topdir, clean_all, search_file)
					# trace-files will be cleaned only when clean all
					os.path.walk (topdir, clean_trace, search_file)
				else:
					print "Error : directory 1 path doesnt exist %s" %topdir
					
			print "\n--------------cleaned---------------\n"
			return 0
		
		if option == '-h' :
			help_sec ()
			return 0
		if option == '-E':
			executable_path = parameter
                        print "Info: executable path set to " + executable_path
						
		if option == '-j' :
			jobs = parameter

		if option == '-t' :
			timeout = parameter

		if option == '-T' :
			generate_detailed_trace = option

		if option == '-s' :
			single_stepping_enabled = option

                if option == '-p':
                        remap = option

                if option == '-L':
                        link = option
 
		if option == '-l' :
            		trace_option = option
			generate_trace = 1

			
	if jobs == "" :
		print "Error in Usage: -j <n-parallel-jobs> not specified."
		return 1
	
	if timeout == "" :
		print "Error in Usage: -t <timeout-in-seconds> not specified."
		return 1



        e_option = " "
        if executable_path != None:
                e_option = " -E " + executable_path
		if not os.path.exists (executable_path):
			print "Error : terminating validation, cannot find processor executable " + executable_path
			return 1
		joblog = path_joblogfile
		srch_file = path_src_file_list_file
		terminal_log = path_term_log


	# clear compiled, log directories generated by previous execution
	# check whether root dirs exist or not
	
	for topdir in args:
		if os.path.exists (topdir):
			os.path.walk (topdir, clean_all, search_file)
		else:
			print "ERROR : directory p ath doesnt exist %s" %topdir
			
	# create a file to store .vprj paths
	obj =  open (srch_file, 'w')
	temp.append(search_file)
	temp.append(obj)
	temp.append(ignore_fpu)
	temp.append(generate_trace)


	# search in all root paths and write in file
	for topdir in args:
		os.path.walk (topdir, array, temp)
	obj.close()
	
		
	# call other script using parallel and test file as
	# argument, test file have absolute paths of
	# all .vprj files
	# "-j + x" - x is number of jobs
	# "--timeout x" - x is timeout time in secs, timeout accuracy is 2 secs
	# for ms enter like 0.2 ms = 0.0002 s
	
	timeout = str(timeout)
	jobs = str(jobs)		

	os.system ("time " + "parallel --gnu " + "--timeout " + timeout + " --joblog " + joblog + " -j" + jobs 
	+ " -a " + srch_file + " python " + path_validation_inner + " " + e_option  + trace_option + " " + single_stepping_enabled + " " + remap + " "  + link + " " + generate_detailed_trace +  " "  + " 2>&1 |" + " tee " + terminal_log)
	

	# calculate run time and failed cases from
	# log file of jobs generated by parallel

	
	with open(joblog) as openfile:
		start = False
		failed_cases = 0
		total_time = 0
		for line in openfile:
			if start:
				temp = line.split("	")
				# 0-success
				if (int(temp[6]) != 0):
					failed_cases = failed_cases + 1
				total_time = total_time + float(temp[3])
			if not start:
				start = True

	# calculate total vprjs
	with open(srch_file) as obj:
		lines = len(obj.readlines())

	ret = failed_cases
	failed_cases = str(failed_cases)
	total_time = str(total_time)
	lines = str(lines)
	
	# tee -a => append
	os.system ("echo " + "Note : total failed cases = " + failed_cases + " |"  + " tee -a " + terminal_log)
	os.system ("echo " + "Note : total time taken by all jobs = " + total_time + " s"+ " |"  + " tee -a " + terminal_log)
	os.system ("echo " + "Note : total vprj = " + lines + " |"  + " tee -a " + terminal_log)
	#print "Note : See %s for exact status of each program" %joblog
	print "Note : In validation job log, Exitval = '0'-no error, '1'-error, '-1'-timeout (program hanging or testbench hanging)"
	return ret
	
if __name__ == '__main__':

	ret = main()
	sys.exit(ret)
