Dump of assembler code for function main:
   0x00000000 <+0>:	82 80 40 22	adddcc  %g1, %g2, %g1
   0x00000004 <+4>:	84 80 80 24	adddcc  %g2, %g4, %g2
   0x00000008 <+8>:	82 00 40 22	addd  %g1, %g2, %g1
   0x0000000c <+12>:	84 00 80 24	addd  %g2, %g4, %g2
   0x00000010 <+16>:	89 68 81 01	adddreduce16  %g2, %g1, %g4
   0x00000014 <+20>:	89 68 80 81	adddreduce8  %g2, %g1, %g4
   0x00000018 <+24>:	82 88 40 22	anddcc  %g1, %g2, %g1
   0x0000001c <+28>:	82 08 40 22	andd  %g1, %g2, %g1
   0x00000020 <+32>:	82 a8 40 22	anddncc  %g1, %g2, %g1
   0x00000024 <+36>:	82 28 40 22	anddn  %g1, %g2, %g1
   0x00000028 <+40>:	89 78 81 01	anddreduce16  %g2, %g1, %g4
   0x0000002c <+44>:	89 78 80 81	anddreduce8  %g2, %g1, %g4
   0x00000030 <+48>:	c9 f8 af ff	cswapa  [ %g2 + 0xfff ], %g4
   0x00000034 <+52>:	c9 f8 81 41	cswapa  [ %g2 + %g1 ] (10), %g4
   0x00000038 <+56>:	c9 7f bf f8	cswap  [ %fp + -8 ], %g4
   0x0000003c <+60>:	c9 78 af ff	cswap  [ %g2 + 0xfff ], %g4
   0x00000040 <+64>:	c9 78 81 01	cswap  [ %g2 + %g1 ] (8), %g4
   0x00000044 <+68>:	89 a0 aa 00	faddreduce16  %f2, %f4
   0x00000048 <+72>:	87 a0 6a 40	fhtos  %f1, %f3
   0x0000004c <+76>:	87 a0 6a 20	fstoh  %f1, %f3
   0x00000050 <+80>:	82 90 40 22	ordcc  %g1, %g2, %g1
   0x00000054 <+84>:	82 10 40 22	ord  %g1, %g2, %g1
   0x00000058 <+88>:	82 b0 40 22	ordncc  %g1, %g2, %g1
   0x0000005c <+92>:	82 30 40 22	ordn  %g1, %g2, %g1
   0x00000060 <+96>:	89 70 81 01	ordreduce16  %g2, %g1, %g4
   0x00000064 <+100>:	89 70 80 81	ordreduce8  %g2, %g1, %g4
   0x00000068 <+104>:	9d e3 bf 88	save  %sp, -120, %sp
   0x0000006c <+108>:	82 f8 40 22	sdivdcc  %g1, %g2, %g1
   0x00000070 <+112>:	82 78 40 22	sdivd  %g1, %g2, %g1
   0x00000074 <+116>:	85 28 60 98	slld  %g1, 0x18, %g2
   0x00000078 <+120>:	85 28 40 83	slld  %g1, %g3, %g2
   0x0000007c <+124>:	a5 28 a0 82	slld  %g2, 2, %l2
   0x00000080 <+128>:	a5 28 80 84	slld  %g2, %g4, %l2
   0x00000084 <+132>:	80 d8 40 22	smuldcc  %g1, %g2, %g0
   0x00000088 <+136>:	80 58 40 22	smuld  %g1, %g2, %g0
   0x0000008c <+140>:	80 58 40 02	smul  %g1, %g2, %g0
   0x00000090 <+144>:	85 38 60 98	srad  %g1, 0x18, %g2
   0x00000094 <+148>:	85 38 40 83	srad  %g1, %g3, %g2
   0x00000098 <+152>:	a1 38 a0 82	srad  %g2, 2, %l0
   0x0000009c <+156>:	a1 38 80 84	srad  %g2, %g4, %l0
   0x000000a0 <+160>:	85 30 60 98	srld  %g1, 0x18, %g2
   0x000000a4 <+164>:	85 30 40 83	srld  %g1, %g3, %g2
   0x000000a8 <+168>:	8d 30 a0 82	srld  %g2, 2, %g6
   0x000000ac <+172>:	8d 30 80 84	srld  %g2, %g4, %g6
   0x000000b0 <+176>:	82 a0 40 22	subdcc  %g1, %g2, %g1
   0x000000b4 <+180>:	84 a0 80 24	subdcc  %g2, %g4, %g2
   0x000000b8 <+184>:	82 20 40 22	subd  %g1, %g2, %g1
   0x000000bc <+188>:	84 20 80 24	subd  %g2, %g4, %g2
   0x000000c0 <+192>:	8c f0 40 22	udivdcc  %g1, %g2, %g6
   0x000000c4 <+196>:	82 70 40 22	udivd  %g1, %g2, %g1
   0x000000c8 <+200>:	84 70 40 22	udivd  %g1, %g2, %g2
   0x000000cc <+204>:	86 70 40 22	udivd  %g1, %g2, %g3
   0x000000d0 <+208>:	88 70 40 22	udivd  %g1, %g2, %g4
   0x000000d4 <+212>:	8a 70 40 22	udivd  %g1, %g2, %g5
   0x000000d8 <+216>:	8c 70 40 22	udivd  %g1, %g2, %g6
   0x000000dc <+220>:	84 70 80 24	udivd  %g2, %g4, %g2
   0x000000e0 <+224>:	80 d0 40 22	umuldcc  %g1, %g2, %g0
   0x000000e4 <+228>:	80 50 40 22	umuld  %g1, %g2, %g0
   0x000000e8 <+232>:	80 50 40 02	umul  %g1, %g2, %g0
   0x000000ec <+236>:	82 00 41 42	vaddd16  %g1, %g2, %g1
   0x000000f0 <+240>:	8c 00 81 44	vaddd16  %g2, %g4, %g6
   0x000000f4 <+244>:	82 00 42 42	vaddd32  %g1, %g2, %g1
   0x000000f8 <+248>:	8c 00 82 44	vaddd32  %g2, %g4, %g6
   0x000000fc <+252>:	82 00 40 c2	vaddd8  %g1, %g2, %g1
   0x00000100 <+256>:	8c 00 80 c4	vaddd8  %g2, %g4, %g6
   0x00000104 <+260>:	8d a0 a8 64	vfadd16  %f2, %f4, %f6
   0x00000108 <+264>:	8d a0 a8 44	vfadd32  %f2, %f4, %f6
   0x0000010c <+268>:	8d a0 a8 e4	vfmul16  %f2, %f4, %f6
   0x00000110 <+272>:	8d a0 a8 c4	vfmul32  %f2, %f4, %f6
   0x00000114 <+276>:	8d a0 a8 a4	vfsub16  %f2, %f4, %f6
   0x00000118 <+280>:	8d a0 a8 84	vfsub32  %f2, %f4, %f6
   0x0000011c <+284>:	82 58 41 42	vsmuld16  %g1, %g2, %g1
   0x00000120 <+288>:	8c 58 81 44	vsmuld16  %g2, %g4, %g6
   0x00000124 <+292>:	82 58 42 42	vsmuld32  %g1, %g2, %g1
   0x00000128 <+296>:	8c 58 82 44	vsmuld32  %g2, %g4, %g6
   0x0000012c <+300>:	82 58 40 c2	vsmuld8  %g1, %g2, %g1
   0x00000130 <+304>:	8c 58 80 c4	vsmuld8  %g2, %g4, %g6
   0x00000134 <+308>:	82 20 41 42	vsubd16  %g1, %g2, %g1
   0x00000138 <+312>:	8c 20 81 44	vsubd16  %g2, %g4, %g6
   0x0000013c <+316>:	82 20 42 42	vsubd32  %g1, %g2, %g1
   0x00000140 <+320>:	8c 20 82 44	vsubd32  %g2, %g4, %g6
   0x00000144 <+324>:	82 20 40 c2	vsubd8  %g1, %g2, %g1
   0x00000148 <+328>:	8c 20 80 c4	vsubd8  %g2, %g4, %g6
   0x0000014c <+332>:	82 50 41 42	vumuld16  %g1, %g2, %g1
   0x00000150 <+336>:	8c 50 81 44	vumuld16  %g2, %g4, %g6
   0x00000154 <+340>:	82 50 42 42	vumuld32  %g1, %g2, %g1
   0x00000158 <+344>:	8c 50 82 44	vumuld32  %g2, %g4, %g6
   0x0000015c <+348>:	82 50 40 c2	vumuld8  %g1, %g2, %g1
   0x00000160 <+352>:	8c 50 80 c4	vumuld8  %g2, %g4, %g6
   0x00000164 <+356>:	82 b8 40 22	xnordcc  %g1, %g2, %g1
   0x00000168 <+360>:	82 38 40 22	xnord  %g1, %g2, %g1
   0x0000016c <+364>:	82 98 40 22	xordcc  %g1, %g2, %g1
   0x00000170 <+368>:	89 f0 81 01	xordreduce16  %g2, %g1, %g4
   0x00000174 <+372>:	89 f0 80 81	xordreduce8  %g2, %g1, %g4
   0x00000178 <+376>:	89 f8 a0 ff	zbytedpos  %g2, 0xff, %g4
   0x0000017c <+380>:	89 f8 80 01	zbytedpos  %g2, %g1, %g4
   0x00000180 <+384>:	01 00 00 00	nop 
End of assembler dump.
